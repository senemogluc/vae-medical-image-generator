{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with MNIST "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Implement LeNet with PyTorch, but with own Convolution and Subsampling/Pooling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.utils import check_random_state\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28b55ae2110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 128\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "# set the seed\n",
    "seed = 42\n",
    "# use a gpu if one is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Training Samples: 48000\n",
      "Number Validation Samples: 11904\n",
      "Number Test Samples: 9984\n"
     ]
    }
   ],
   "source": [
    "# create the transformations\n",
    "normalization = transforms.Normalize((0.1306,), (0.3015,))\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(), normalization])\n",
    "# in this case we are using the same transformations for training and testing\n",
    "train_transforms = test_transforms\n",
    "\n",
    "# get the training and testing datasets\n",
    "train_data = datasets.MNIST(root = 'data', train = True, download = True, transform=train_transforms)\n",
    "valid_data = datasets.MNIST(root = 'data', train = True, download = True, transform=test_transforms)\n",
    "test_data = datasets.MNIST(root = 'data', train = False, download = True, transform=test_transforms)\n",
    "\n",
    "# split the training data into train and validation data\n",
    "indices = np.arange(len(train_data))\n",
    "train_indices, valid_indices = train_test_split(indices, test_size=valid_size, random_state=seed, stratify=train_data.targets)\n",
    "\n",
    "# create the data loaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n",
    "                                           sampler = train_sampler, num_workers = num_workers, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size,\n",
    "                                          sampler = valid_sampler, num_workers = num_workers, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size,\n",
    "                                         num_workers = num_workers, drop_last=True)\n",
    "\n",
    "print(f'Number Training Samples: {len(train_loader) * batch_size}')\n",
    "print(f'Number Validation Samples: {len(valid_loader) * batch_size}')\n",
    "print(f'Number Test Samples: {len(test_loader) * batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Compose' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Compose' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "test_transforms.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Own Convolutional and Pooling Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWindowOperation(nn.Module):\n",
    "    def __init__(self, kernel_size, padding=0, stride=1, dilation=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # define all dimensions we need\n",
    "        self.kernel_size = kernel_size if hasattr(kernel_size, '__iter__') else (kernel_size, kernel_size)\n",
    "        self.dilation = dilation if hasattr(dilation, '__iter__') else (dilation, dilation)\n",
    "        self.padding = padding if hasattr(padding, '__iter__') else (padding, padding)\n",
    "        self.stride = stride if hasattr(stride, '__iter__') else (stride, stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplemented('This function is not implemented yet. Please implement in subclass')\n",
    "    \n",
    "    def calculateWindows(self, x):\n",
    "        # get the windows/patches along the height\n",
    "        windows = F.unfold(x, kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding, stride=self.stride)\n",
    "        # switch the number of windows with the number of values per window\n",
    "        windows = windows.transpose(1, 2) # (batch_dim, num_windows, num_values_per_window)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        # the formula to calculate the output size is: ((input - kernel_size + 2 * padding) / stride) + 1\n",
    "        input_width = x.shape[-2]\n",
    "\n",
    "        return (\n",
    "            (input_width + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        input_height = x.shape[-1]\n",
    "\n",
    "        return (\n",
    "            (input_height + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1\n",
    "\n",
    "class MyConv2d(MyWindowOperation):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1, dilation=1):\n",
    "        super().__init__(kernel_size=kernel_size, dilation=dilation, padding=padding, stride=stride)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # parameters of conv layer\n",
    "        self.weights = nn.Parameter(torch.ones(self.out_channels, self.in_channels, *self.kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros((self.out_channels)))\n",
    "\n",
    "        # init parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.weights)\n",
    "        nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        is_batched = len(x.shape) > 3\n",
    "        if not is_batched:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        batch_size = x.shape[0]\n",
    "    \n",
    "        # get the width, heigth of the output\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        # get all the windows on the input\n",
    "        windows = self.calculateWindows(x) # (batch_size, num_windows, num_values_per_window)\n",
    "\n",
    "        res = windows.matmul(self.weights.view(self.out_channels, -1).T) + self.bias # (batch_size, num_windows, out_channels)\n",
    "        res = res.transpose(1, 2) # (batch_size, out_channels, num_windows)\n",
    "        \n",
    "        # view the result\n",
    "        res = res.view(batch_size, self.out_channels, height, width)\n",
    "\n",
    "        # if the input is not batched remove the batch size of 1 at the first dimension\n",
    "        if not is_batched:\n",
    "            res = res.squeeze(0)\n",
    "\n",
    "        return res \n",
    "    \n",
    "\n",
    "class MyAvgPool2d(MyWindowOperation):\n",
    "    def __init__(self, kernel_size, padding=0, stride=1, dilation=1, ):\n",
    "        super().__init__(kernel_size=kernel_size, dilation=dilation, padding=padding, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        is_batched = len(x.shape) > 3\n",
    "        if not is_batched:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        batch_size = x.shape[0]\n",
    "        num_channels = x.shape[1]\n",
    "    \n",
    "        # get the width, heigth of the output\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        # get all the windows on the input\n",
    "        windows = self.calculateWindows(x) # (batch_size, num_windows, num_values_per_window)\n",
    "\n",
    "        # get the average across the values of each window\n",
    "        res = windows.contiguous().view(batch_size, num_channels, -1, self.kernel_size[0] * self.kernel_size[1]).mean(-1) \n",
    "        \n",
    "        # view the result\n",
    "        res = res.view(batch_size, -1, height, width)\n",
    "\n",
    "        # if the input is not batched remove the batch size of 1 at the first dimension\n",
    "        if not is_batched:\n",
    "            res = res.squeeze(0)\n",
    "\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img):\n",
    "    plt.imshow(img.permute(1, 2, 0), cmap=plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the test image for visualizing\n",
    "test_image, test_image_label = train_data[0]\n",
    "print(f'Label: {5}')\n",
    "visualize(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the convolution implementation is correct\n",
    "my_conv = MyConv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "pt_conv = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "\n",
    "my_conv_weight = my_conv.weights.data.numpy()\n",
    "my_conv_bias = my_conv.bias.data.numpy()\n",
    "print(f'Shape Bias: {my_conv_bias.shape}')\n",
    "print(f'Shape Weights: {my_conv_weight.shape}')\n",
    "\n",
    "# to test whether our calculations are correct assign the same weights\n",
    "my_conv.weights = pt_conv.weight\n",
    "my_conv.bias = pt_conv.bias\n",
    "\n",
    "assert (my_conv.weights == pt_conv.weight).all()\n",
    "assert (my_conv.bias == pt_conv.bias).all()\n",
    "\n",
    "print(f'Visualizing first kernel:')\n",
    "plt.imshow(my_conv.weights.data.numpy()[0, 0, ...])\n",
    "plt.show()\n",
    "\n",
    "my_conv_res = my_conv(test_image)\n",
    "pt_conv_res = pt_conv(test_image)\n",
    "assert my_conv_res.shape == pt_conv_res.shape\n",
    "\n",
    "print(f'Abs Error: {(pt_conv_res - my_conv_res).abs().max()}')\n",
    "print(f'Output Shape: {my_conv_res.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, my_conv_res.shape[0] + 1, figsize=(15, 5))\n",
    "axs[0].imshow(test_image.permute(1, 2, 0), cmap=plt.cm.gray)\n",
    "for i in range(my_conv_res.shape[0]):\n",
    "   axs[i+1].imshow(my_conv_res[i:i+1].detach().permute(1, 2, 0), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the pooling implementation is correct\n",
    "my_pool = MyAvgPool2d(kernel_size=2, stride=2)\n",
    "pt_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "my_pool_res = my_pool(test_image)\n",
    "pt_pool_res = pt_pool(test_image)\n",
    "assert my_conv_res.shape == pt_conv_res.shape\n",
    "\n",
    "print(f'Abs Error: {(pt_pool_res - my_pool_res).abs().max()}')\n",
    "print(f'Output Shape: {my_pool_res.shape}\\n')\n",
    "\n",
    "visualize(my_pool_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define own model = LeCun ConvNet\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, own_conv=True, own_pool=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # define which convolution to use\n",
    "        if own_conv:\n",
    "            print(\"Using own conv\")\n",
    "            self.conv1 = MyConv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "            self.conv2 = MyConv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        else:\n",
    "            print(\"Using pytorch conv\")\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "            self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # define which pooling layer to use\n",
    "        if own_pool:\n",
    "            print(\"Using own pooling layer\")\n",
    "            self.pool = MyAvgPool2d(kernel_size=2, stride=2)\n",
    "        else:\n",
    "            print(\"Using pytorch pooling layer\")\n",
    "            self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.output = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.sigmoid(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # flatten the convolution results\n",
    "        x = x.view(-1, 16*5*5)\n",
    "\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "\n",
    "        return self.output(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, train_loader, val_loader, test_loader, epochs=200, lr=1e-3):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "    \n",
    "    num_train_samples = (len(train_loader) * train_loader.batch_size)\n",
    "    num_val_samples = (len(val_loader) * val_loader.batch_size)\n",
    "    num_test_samples = (len(test_loader) * test_loader.batch_size)\n",
    "\n",
    "    best_model_valid_loss = np.Inf\n",
    "    num_epochs_without_val_loss_reduction = 0\n",
    "    early_stopping_window = 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_train_loss = 0\n",
    "        running_val_loss = 0\n",
    "\n",
    "        correct_train_preds = 0\n",
    "        correct_val_preds = 0\n",
    "\n",
    "        # iterate the training data\n",
    "        with tqdm(train_loader, desc=\"Training\") as train_epoch_pbar:\n",
    "            for i, (x, y) in enumerate(train_epoch_pbar):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = network(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_train_loss += loss * len(x)\n",
    "                correct_train_preds += (logits.argmax(-1) == y).sum()\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    # we can divide by (i * len(x)) because we are dropping the last batch\n",
    "                    num_train_samples_so_far = (i + 1) * len(x)\n",
    "                    train_epoch_pbar.set_postfix(train_loss=running_train_loss.item() / num_train_samples_so_far, accuracy=correct_train_preds.item() / num_train_samples_so_far * 100)\n",
    "\n",
    "        # iterate the val data\n",
    "        with tqdm(val_loader, desc=\"Validating\") as val_epoch_pbar:\n",
    "            for i, (x, y) in enumerate(val_epoch_pbar):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = network(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "                running_val_loss += loss * len(x)\n",
    "                correct_val_preds += (logits.argmax(-1) == y).sum()\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    num_val_samples_so_far = (i + 1) * len(x)\n",
    "                    val_epoch_pbar.set_postfix(train_loss=running_val_loss.item() / num_val_samples_so_far, accuracy=correct_val_preds.item() / num_val_samples_so_far * 100)\n",
    "\n",
    "        \n",
    "        avg_train_loss = running_train_loss.item() / num_train_samples\n",
    "        train_acc = correct_train_preds.item() / num_train_samples * 100\n",
    "        avg_val_loss = running_val_loss.item() / num_val_samples\n",
    "        val_acc = correct_val_preds.item() / num_val_samples * 100\n",
    "\n",
    "        print(f'Epoch {epoch}: \\tAvg Train Loss: {avg_train_loss:.2f} \\tTrain Acc: {train_acc:.2f} \\tAvg Val Loss: {avg_val_loss:.2f} \\tVal Acc: {val_acc:.2f}')\n",
    "\n",
    "        # perform early stopping if necessary\n",
    "        if avg_val_loss <= best_model_valid_loss:\n",
    "            print(f'Validation loss decreased ({best_model_valid_loss:.6f} --> {avg_val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(network.state_dict(), 'model.pt')\n",
    "            best_model_valid_loss = avg_val_loss\n",
    "            num_epochs_without_val_loss_reduction = 0\n",
    "        else:\n",
    "            num_epochs_without_val_loss_reduction += 1\n",
    "        \n",
    "        if num_epochs_without_val_loss_reduction >= early_stopping_window:\n",
    "            # if we haven't had a reduction in validation loss for `early_stopping_window` epochs, then stop training\n",
    "            print(f'No reduction in validation loss for {early_stopping_window} epochs. Stopping training...')\n",
    "            break\n",
    "\n",
    "\n",
    "    running_test_loss = 0\n",
    "    correct_test_preds = 0\n",
    "    # only after finishing training we are testing our model\n",
    "    with tqdm(test_loader, desc=\"Testing\") as test_pbar:\n",
    "        for i, (x, y) in enumerate(test_pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = network(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            running_test_loss += loss * len(x)\n",
    "            correct_test_preds += (logits.argmax(-1) == y).sum()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                num_test_samples_so_far = (i + 1) * len(x)\n",
    "                val_epoch_pbar.set_postfix(train_loss=running_test_loss.item() / num_test_samples_so_far, accuracy=correct_test_preds.item() / num_test_samples_so_far * 100)\n",
    "\n",
    "    avg_test_loss = running_test_loss.item() / num_test_samples\n",
    "    test_acc = correct_test_preds.item() / num_test_samples * 100\n",
    "    \n",
    "    print(f'Test Set: \\tAvg Test Loss: {avg_test_loss:.2f} \\tTest Acc: {test_acc:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ConvNet(own_conv=True, own_pool=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, valid_loader, test_loader, epochs=200, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "filter_output = model.conv1(test_image)\n",
    "fig, axs = plt.subplots(1, filter_output.shape[0] + 1, figsize=(15, 5))\n",
    "axs[0].imshow(test_image.permute(1, 2, 0), cmap=plt.cm.gray)\n",
    "for i in range(filter_output.shape[0]):\n",
    "    axs[i + 1].imshow(filter_output[i:i + 1].detach().permute(1, 2, 0), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
